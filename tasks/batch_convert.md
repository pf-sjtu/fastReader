# 云端处理结果缓存读取+批量处理

对于图书内容总结功能，扩充云端处理结果缓存读取+批量处理功能

你理解这个应用本质上是epub/pdf to md并且上传，现在加：

## 缓存读取
实质是md复原渲染逻辑。

每次打开pdf或者图书时，以文件名和路径匹配尝试读取网盘中的处理结果，如果存在则直接读取，并且提示用户存在缓存，可以跳过处理直接到结果展示页面（通过已处理文件进行渲染展示，和正常处理后界面和显示效果一致）；否则如无缓存，可进行常规处理流程。

缓存读取路径和文件名和正常处理结束后的保存操作一致。

## 处理信息备注tag
在处理pdf或者图书完成后，在保存处理结果epub文件到网盘时，在内容头部以html备注的方式填写必要的文件说明，比如来源、文件名、处理时间、处理模型、章节读取方式、勾选章节名、章节数量、处理前字数、处理后字数等等你觉得对调试有用的必要信息，顺序按照合理阅读顺序和排版排列，不影响markdown渲染和业务流程读取网盘缓存。

## 批量处理
在“文件上传与配置”部分，WebDAV按钮右侧，加入一个WebDAV批量处理按钮，点击后，可以选择WebDAV中的文件夹进行批量处理，包括：选择文件夹路径、选择处理文件（epub和pdf）数量（可选所有）、处理方式（全部范围、仅未处理部分；顺序/随机。未处理就是未匹配到处理结果缓存的，随机顺序类似断点续传，可以实现仅对未处理部分的处理）。

点击确认后自动把选定内容加入到处理队列（可以理解为原有模式处理队列只有一本书，现在可以有多个）。

可以实时预览队列内容。使用上下滚动UI方式侵占太多屏幕空间。可以在未完成处理前、包括在处理中随时跳过或者删除队列中的个别待处理书记。

尊重配置部分的设置。点击获取章节能获取队列范围内当前待处理的第一本书的章节情况。

可以利用此功能实现对webdav某文件夹内所有合乎标准的图书，以设置内容进行队列处理、完成对全库的处理并且标注备注tag。

## Cli批量处理
设计基于Python和现有代码的cli批量处理工具，符合当前项目逻辑，代码放置于src/cli下。

其通过--config/-c导入一个配置YAML文件，比如@ebook-to-mindmap-config-v2.yaml，即可通过命令行交互设定webdav路径、处理文件数量、处理方式、处理范围、处理顺序、处理模型等参数。进行和网页逻辑一致的、批量文件处理（注意这种方式在上传md到网盘时，行为和现有项目一致，同时会在 @output/ 目录下生成处理结果的md文件）。

注意交互友好、过程提示（支持.env中配置debug=true获得更详细的输出信息）、完全尊重现有业务逻辑，并且不影响现有项目。

注意实现一定的错误兼容和log（在log文件夹，比如在某图书处理出错的时候重试几次、之后跳过，在无法连接到webdav的时候提示错误、跳过等等）

注意合理设置工作流程，比如对于要处理的图书队列，可以先从webdav读取队列首个，在处理的过程中在本地建立一个待处理图书batch，比如min(要求处理数量, 10)本，待处理到倒数第二本的时候，再次请求webdav补充队列，这样减少服务器负担，output上传也遵循同样技术，超参数可以在env中配置，也有默认值。

注意这样批量生成出来的md文档，兼容网页版打开时候的缓存读取逻辑。

## 注意
更新文档。提示之后修改主程序逻辑或者批量处理逻辑的时候，要同步修改。